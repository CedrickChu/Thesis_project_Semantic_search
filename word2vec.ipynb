{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "import pymongo\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import gensim.models as gm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb+srv://cedrickchu123:lzuaguRde81CZVuD@cluster0.75dzsfe.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "db = client.ThesisProject\n",
    "collection = db.Thesis_Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial',\n",
       " 'intelligence',\n",
       " 'ai',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'ml',\n",
       " 'becoming',\n",
       " 'increasingly',\n",
       " 'ubiquitous',\n",
       " 'everyday',\n",
       " 'lives',\n",
       " 'despite',\n",
       " 'rapid',\n",
       " 'pace',\n",
       " 'developments',\n",
       " 'debates',\n",
       " 'around',\n",
       " 'responsible',\n",
       " 'ai',\n",
       " 'ai',\n",
       " 'go']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(collection.find_one()['abstract'][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def sentence_tokenization(text: str) -> List[List[str]]:\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(text)]\n",
    "    return tokenized_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Artificial',\n",
       "  'Intelligence',\n",
       "  '(',\n",
       "  'AI',\n",
       "  ')',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  '(',\n",
       "  'ML',\n",
       "  ')',\n",
       "  'are',\n",
       "  'becoming',\n",
       "  'increasingly',\n",
       "  'ubiquitous',\n",
       "  'in',\n",
       "  'our',\n",
       "  'everyday',\n",
       "  'lives',\n",
       "  '.'],\n",
       " ['Despite',\n",
       "  'the',\n",
       "  'rapid',\n",
       "  'pace',\n",
       "  'of',\n",
       "  'these',\n",
       "  'developments',\n",
       "  ',',\n",
       "  'debates',\n",
       "  'around',\n",
       "  'responsible',\n",
       "  'AI',\n",
       "  'and',\n",
       "  'AI',\n",
       "  'go']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokenization(collection.find_one()['abstract'][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(text: str) -> List[str]:\n",
    "    word_tokens = preprocess_text(text)\n",
    "    sentence_tokens = sentence_tokenization(text)\n",
    "    corpus = word_tokens + [word for sentence in sentence_tokens for word in sentence]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec_model(corpus):\n",
    "    VECTOR_SIZE = 300\n",
    "    WINDOW = 30 \n",
    "    MIN_COUNT = 3\n",
    "    SG = 2\n",
    "    model = Word2Vec(\n",
    "        sentences=[corpus], \n",
    "        vector_size=VECTOR_SIZE,\n",
    "        window=WINDOW,\n",
    "        min_count=MIN_COUNT,\n",
    "        sg=SG\n",
    "    )\n",
    "    model.save('word2vec_model.gensim')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'intelligence', 'ai', 'machine', 'learning', 'ml', 'becoming', 'increasingly', 'ubiquitous', 'everyday', 'lives', 'despite', 'rapid', 'pace', 'developments', 'debates', 'around', 'responsible', 'ai', 'ai', 'governance', 'still', 'maturing', 'paper', 'outlines', 'growth', 'ethical', 'ai', 'movement', 'internationally', 'nationally', 'provide', 'context', 'caidgs', 'ethics', 'hub', 'initiative', 'touches', 'open', 'questions', 'field', 'discusses', 'questions', 'influenced', 'trajectory', 'hubs', 'research', 'methodologies', 'paper', 'reflects', 'piloted', 'empirical', 'exercises', 'charts', 'research', 'questions', 'developed', 'changed', 'time', 'along', 'way', 'identified', 'themes', 'power', 'resource', 'differentials', 'well', 'communication', 'breakdowns', 'shaped', 'latter', 'stages', 'project', 'given', 'nature', 'pilot', 'project', 'findings', 'indicative', 'generalizable', 'entire', 'field', 'singapore', 'nonetheless', 'represent', 'meaningful', 'snapshot', 'debates', 'around', 'ethical', 'ai', 'operationalization', 'unfolding', 'singapore', 'beyond', 'ultimately', 'encourage', 'focused', 'research', 'development', 'design', 'institutional', 'incentive', 'mechanisms', 'foster', 'greater', 'cohesion', 'around', 'responsible', 'ai', 'development', 'deployment', 'norms', 'automatic', 'facial', 'expression', 'recognition', 'systems', 'come', 'long', 'way', 'since', 'earliest', 'approaches', 'early', '1970s', 'point', 'earliest', 'systems', 'commercially', 'applied', 'notably', 'smile', 'detectors', 'digital', 'cameras', 'although', 'facial', 'expression', 'recognition', 'maturing', 'research', 'field', 'far', 'finished', 'new', 'techniques', 'continue', 'developed', 'aspects', 'processing', 'pipeline', 'face', 'detection', 'via', 'feature', 'extraction', 'machine', 'learning', 'field', 'blind', 'progress', 'made', 'social', 'sciences', 'respect', 'emotion', 'theory', 'gone', 'days', 'people', 'tried', 'detect', 'six', 'discrete', 'expressions', 'turnedon', 'like', 'switching', 'lights', 'theory', 'social', 'signal', 'processing', 'complements', 'classical', 'emotion', 'theory', 'modern', 'approaches', 'dissect', 'expression', 'temporal', 'phases', 'analyse', 'intensity', 'symmetry', 'microexpressions', 'dynamic', 'differences', 'morphologically', 'similar', 'expressions', 'brave', 'new', 'worlds', 'opened', 'upautomatic', 'facial', 'expression', 'analysis', 'poised', 'revolutionalise', 'medicine', 'advent', 'behaviomedics', 'gaming', 'enriched', 'playernonplayer', 'interactions', 'teleconference', 'meetings', 'automatic', 'trust', 'engagement', 'analysis', 'humanrobot', 'interaction', 'robots', 'displaying', 'actual', 'empathy', 'volume', 'complete', 'fouryear', 'term', 'executive', 'editor', 'machine', 'learning', 'tom', 'dietterich', 'coexecutive', 'editor', 'recently', 'takes', 'helmor', 'starts', 'serving', 'sentence', 'depending', 'upon', 'ones', 'point', 'view', 'let', 'take', 'opportunity', 'make', 'reflections', 'state', 'field', 'past', 'present', 'future', 'based', 'personal', 'observations', 'decade', 'ago', 'machine', 'learning', 'regrouping', 'rather', 'uneventful', '1970s', 'first', 'machine', 'learning', 'workshop', 'held', '1980', 'carnegie', 'mellon', 'university', 'two', 'dozen', 'participants', 'photocopied', 'preprints', 'shortly', 'thereafter', 'started', 'preparing', 'first', 'machine', 'learning', 'book', 'charge', 'finding', 'publication', 'venue', 'however', 'title', 'machine', 'learning', 'raised', 'skeptical', 'eyebrows', 'publishers', 'machine', 'learning', 'really', 'mean', 'learning', 'machines', 'rather', 'learning', 'machines', 'couldnt', 'think', 'something', 'scientificsounding', 'call', 'book', 'anyway', 'hadnt', 'minsky', 'papert', 'debunked', 'learning', 'nonsense', 'since', 'proved', 'difficult', 'explain', 'difference', 'linear', 'perceptrons', 'symbolic', 'learning', 'publishers', 'shall', 'go', 'unnamed', 'protect', 'guilty', 'approached', 'nils', 'nilsson', 'tioga', 'press', 'nils', 'embraced', 'project', 'foresight', 'enthusiasm', 'rest', 'say', 'tired', 'cliche', 'history', 'existing', 'augmented', 'reality', 'ar', 'mixed', 'reality', 'mr', 'systems', 'able', 'understand', '3d', 'geometry', 'surroundings', 'lack', 'ability', 'detect', 'classify', 'complex', 'objects', 'real', 'world', 'capabilities', 'enabled', 'deep', 'convolutional', 'neural', 'networks', 'cnn', 'remains', 'difficult', 'execute', 'large', 'networks', 'mobile', 'devices', 'offloading', 'object', 'detection', 'edge', 'cloud', 'also', 'challenging', 'due', 'stringent', 'requirements', 'high', 'detection', 'accuracy', 'low', 'endtoend', 'latency', 'long', 'latency', 'existing', 'offloading', 'techniques', 'significantly', 'reduce', 'detection', 'accuracy', 'due', 'changes', 'users', 'view', 'address', 'problem', 'design', 'system', 'enables', 'high', 'accuracy', 'object', 'detection', 'commodity', 'armr', 'system', 'running', '60fps', 'system', 'employs', 'low', 'latency', 'offloading', 'techniques', 'decouples', 'rendering', 'pipeline', 'offloading', 'pipeline', 'uses', 'fast', 'object', 'tracking', 'method', 'maintain', 'detection', 'accuracy', 'result', 'shows', 'system', 'improve', 'detection', 'accuracy', '202348', 'object', 'detection', 'human', 'keypoint', 'detection', 'tasks', 'requires', '224ms', 'latency', 'object', 'tracking', 'ar', 'device', 'thus', 'system', 'leaves', 'time', 'computational', 'resources', 'render', 'virtual', 'elements', 'next', 'frame', 'enables', 'higher', 'quality', 'armr', 'experiences', 'present', 'yolo', 'new', 'approach', 'object', 'detection', 'prior', 'work', 'object', 'detection', 'repurposes', 'classifiers', 'perform', 'detection', 'instead', 'frame', 'object', 'detection', 'regression', 'problem', 'spatially', 'separated', 'bounding', 'boxes', 'associated', 'class', 'probabilities', 'single', 'neural', 'network', 'predicts', 'bounding', 'boxes', 'class', 'probabilities', 'directly', 'full', 'images', 'one', 'evaluation', 'since', 'whole', 'detection', 'pipeline', 'single', 'network', 'optimized', 'endtoend', 'directly', 'detection', 'performance', 'unified', 'architecture', 'extremely', 'fast', 'base', 'yolo', 'model', 'processes', 'images', 'realtime', '45', 'frames', 'per', 'second', 'smaller', 'version', 'network', 'fast', 'yolo', 'processes', 'astounding', '155', 'frames', 'per', 'second', 'still', 'achieving', 'double', 'map', 'realtime', 'detectors', 'compared', 'stateoftheart', 'detection', 'systems', 'yolo', 'makes', 'localization', 'errors', 'less', 'likely', 'predict', 'false', 'positives', 'background', 'finally', 'yolo', 'learns', 'general', 'representations', 'objects', 'outperforms', 'detection', 'methods', 'including', 'dpm', 'rcnn', 'generalizing', 'natural', 'images', 'domains', 'like', 'artwork', 'deep', 'learning', 'allows', 'computational', 'models', 'composed', 'multiple', 'processing', 'layers', 'learn', 'representations', 'data', 'multiple', 'levels', 'abstraction', 'methods', 'dramatically', 'improved', 'stateoftheart', 'speech', 'recognition', 'visual', 'object', 'recognition', 'object', 'detection', 'many', 'domains', 'drug', 'discovery', 'genomics', 'deep', 'learning', 'discovers', 'intricate', 'structure', 'large', 'data', 'sets', 'using', 'backpropagation', 'algorithm', 'indicate', 'machine', 'change', 'internal', 'parameters', 'used', 'compute', 'representation', 'layer', 'representation', 'previous', 'layer', 'deep', 'convolutional', 'nets', 'brought', 'breakthroughs', 'processing', 'images', 'video', 'speech', 'audio', 'whereas', 'recurrent', 'nets', 'shone', 'light', 'sequential', 'data', 'text', 'speech', 'deep', 'convolutional', 'neural', 'networks', 'performed', 'remarkably', 'well', 'many', 'computer', 'vision', 'tasks', 'however', 'networks', 'heavily', 'reliant', 'big', 'data', 'avoid', 'overfitting', 'overfitting', 'refers', 'phenomenon', 'network', 'learns', 'function', 'high', 'variance', 'perfectly', 'model', 'training', 'data', 'unfortunately', 'many', 'application', 'domains', 'access', 'big', 'data', 'medical', 'image', 'analysis', 'survey', 'focuses', 'data', 'augmentation', 'dataspace', 'solution', 'problem', 'limited', 'data', 'data', 'augmentation', 'encompasses', 'suite', 'techniques', 'enhance', 'size', 'quality', 'training', 'datasets', 'better', 'deep', 'learning', 'models', 'built', 'using', 'image', 'augmentation', 'algorithms', 'discussed', 'survey', 'include', 'geometric', 'transformations', 'color', 'space', 'augmentations', 'kernel', 'filters', 'mixing', 'images', 'random', 'erasing', 'feature', 'space', 'augmentation', 'adversarial', 'training', 'generative', 'adversarial', 'networks', 'neural', 'style', 'transfer', 'metalearning', 'application', 'augmentation', 'methods', 'based', 'gans', 'heavily', 'covered', 'survey', 'addition', 'augmentation', 'techniques', 'paper', 'briefly', 'discuss', 'characteristics', 'data', 'augmentation', 'testtime', 'augmentation', 'resolution', 'impact', 'final', 'dataset', 'size', 'curriculum', 'learning', 'survey', 'present', 'existing', 'methods', 'data', 'augmentation', 'promising', 'developments', 'metalevel', 'decisions', 'implementing', 'data', 'augmentation', 'readers', 'understand', 'data', 'augmentation', 'improve', 'performance', 'models', 'expand', 'limited', 'datasets', 'take', 'advantage', 'capabilities', 'big', 'data', 'recent', 'work', 'demonstrated', 'deep', 'neural', 'networks', 'vulnerable', 'adversarial', 'examplesinputs', 'almost', 'indistinguishable', 'natural', 'data', 'yet', 'classified', 'incorrectly', 'network', 'fact', 'latest', 'findings', 'suggest', 'existence', 'adversarial', 'attacks', 'may', 'inherent', 'weakness', 'deep', 'learning', 'models', 'address', 'problem', 'study', 'adversarial', 'robustness', 'neural', 'networks', 'lens', 'robust', 'optimization', 'approach', 'provides', 'us', 'broad', 'unifying', 'view', 'much', 'prior', 'work', 'topic', 'principled', 'nature', 'also', 'enables', 'us', 'identify', 'methods', 'training', 'attacking', 'neural', 'networks', 'reliable', 'certain', 'sense', 'universal', 'particular', 'specify', 'concrete', 'security', 'guarantee', 'would', 'protect', 'adversary', 'methods', 'let', 'us', 'train', 'networks', 'significantly', 'improved', 'resistance', 'wide', 'range', 'adversarial', 'attacks', 'also', 'suggest', 'notion', 'security', 'firstorder', 'adversary', 'natural', 'broad', 'security', 'guarantee', 'believe', 'robustness', 'welldefined', 'classes', 'adversaries', 'important', 'stepping', 'stone', 'towards', 'fully', 'resistant', 'deep', 'learning', 'models', 'code', 'pretrained', 'models', 'available', 'https', 'url', 'https', 'url', 'transformer', 'architecture', 'become', 'defacto', 'standard', 'natural', 'language', 'processing', 'tasks', 'applications', 'computer', 'vision', 'remain', 'limited', 'vision', 'attention', 'either', 'applied', 'conjunction', 'convolutional', 'networks', 'used', 'replace', 'certain', 'components', 'convolutional', 'networks', 'keeping', 'overall', 'structure', 'place', 'show', 'reliance', 'cnns', 'necessary', 'pure', 'transformer', 'applied', 'directly', 'sequences', 'image', 'patches', 'perform', 'well', 'image', 'classification', 'tasks', 'pretrained', 'large', 'amounts', 'data', 'transferred', 'multiple', 'midsized', 'small', 'image', 'recognition', 'benchmarks', 'imagenet', 'cifar100', 'vtab', 'etc', 'vision', 'transformer', 'vit', 'attains', 'excellent', 'results', 'compared', 'stateoftheart', 'convolutional', 'networks', 'requiring', 'substantially', 'fewer', 'computational', 'resources', 'train', 'excerpted', 'glimpse', 'continuous', 'realtime', 'object', 'recognition', 'mobile', 'devices', 'proceedings', '13th', 'acm', 'conference', 'embedded', 'networked', 'sensor', 'systems', 'permission', 'httpdxdoiorg10114528096952809711', 'acm', '2015', 'glimpse', 'continuous', 'realtime', 'object', 'recognition', 'system', 'cameraequipped', 'mobile', 'devices', 'glimpse', 'captures', 'fullmotion', 'video', 'locates', 'objects', 'interest', 'recognizes', 'labels', 'tracks', 'frame', 'frame', 'user', 'algorithms', 'object', 'recognition', 'entail', 'significant', 'computation', 'glimpse', 'runs', 'server', 'machines', 'latency', 'server', 'mobile', 'device', 'higher', 'frametime', 'approach', 'lowers', 'object', 'recognition', 'accuracy', 'regain', 'accuracy', 'glimpse', 'uses', 'active', 'cache', 'video', 'frames', 'mobile', 'device', 'subset', 'frames', 'active', 'cache', 'used', 'track', 'objects', 'mobile', 'using', 'stale', 'hints', 'objects', 'arrive', 'server', 'time', 'time', 'reduce', 'network', 'bandwidth', 'usage', 'glimpse', 'computes', 'trigger', 'frames', 'send', 'server', 'recognizing', 'healthcare', 'costs', 'rise', 'united', 'states', 'debate', 'ongoing', 'obtain', 'better', 'value', 'dollars', 'spent', 'context', 'use', 'costeffectiveness', 'analysis', 'cea', 'compelling', 'ever', 'book', 'written', 'second', 'panel', 'costeffectiveness', 'health', 'medicine', 'reviews', 'key', 'concepts', 'analytic', 'challenges', 'cea', 'authors', 'endorse', 'original', 'panels', 'concept', 'reference', 'case', 'support', 'recommendation', 'analysts', 'take', 'broad', 'societal', 'perspective', 'addition', 'recommend', 'healthcare', 'sector', 'perspective', 'second', 'reference', 'case', 'well', 'important', 'new', 'framework', 'impact', 'inventory', 'detailing', 'costs', 'effects', 'revisions', 'draw', 'advances', 'field', 'include', 'three', 'new', 'chapters', 'capture', 'research', 'decision', 'modeling', 'methods', 'evidence', 'synthesis', 'ethical', 'considerations', 'volume', 'also', 'includes', 'two', 'new', 'worked', 'examples', 'appendix', 'appendix', 'b', 'illustrate', 'ways', 'implement', 'authors', 'recommendations', 'abstract', 'delves', 'conceptual', 'framework', 'envisions', 'clinicians', 'caregivers', 'bedside', 'pivotal', 'guardians', 'public', 'health', 'medicine', 'science', 'traditional', 'role', 'clinicians', 'predominantly', 'centered', 'individual', 'patient', 'care', 'yet', 'paradigm', 'proposes', 'expansion', 'responsibilities', 'encompass', 'broader', 'societal', 'wellbeing', 'exploring', 'intersections', 'clinical', 'practice', 'public', 'health', 'initiatives', 'scientific', 'advancements', 'paradigm', 'shift', 'aims', 'harness', 'expertise', 'influence', 'clinicians', 'address', 'systemic', 'health', 'challenges', 'proposed', 'framework', 'emphasizes', 'multifaceted', 'roles', 'clinicians', 'play', 'shaping', 'public', 'health', 'policies', 'advancing', 'medical', 'research', 'fostering', 'culture', 'evidencebased', 'practice', 'drawing', 'case', 'studies', 'theoretical', 'models', 'abstract', 'highlights', 'potential', 'impact', 'empowering', 'clinicians', 'contribute', 'actively', 'public', 'health', 'discourse', 'policy', 'formulation', 'community', 'education', 'underscores', 'importance', 'integrating', 'clinical', 'knowledge', 'scientific', 'inquiry', 'thereby', 'fostering', 'comprehensive', 'approach', 'healthcare', 'transcends', 'confines', 'individual', 'patient', 'interactions', 'new', 'edition', 'wellestablished', 'book', 'thoroughly', 'revised', 'gives', 'comprehensive', 'account', 'role', 'free', 'radicals', 'reactive', 'species', 'rs', 'antioxidants', 'life', 'health', 'disease', 'chapter', '1', 'reviews', 'oxygen', 'o2', 'used', 'living', 'organisms', 'toxic', 'introduces', 'concept', 'oxygen', 'radicals', 'rs', 'chemistry', 'detailed', 'chapter', '2', 'especially', 'superoxide', 'hydroxyl', 'radical', 'including', 'fenton', 'chemistry', 'peroxynitrite', 'nitric', 'oxide', 'ozone', 'singlet', 'o2', 'emphasis', 'redox', 'properties', 'subsequent', 'chapters', 'detail', 'antioxidants', 'made', 'vivo', 'eg', 'superoxide', 'dismutases', 'peroxiredoxins', 'come', 'diet', 'eg', 'vitamins', 'e', 'c', 'carotenoids', 'polyphenols', 'flavonoids', 'work', 'vivo', 'role', 'rs', 'cell', 'proliferation', 'senescence', 'death', 'eg', 'apoptosis', 'necrosis', 'intermediate', 'forms', 'presented', 'methods', 'measuring', 'rs', 'described', 'detail', 'including', 'electron', 'paramagnetic', 'resonance', 'biomarker', 'determination', 'useful', 'roles', 'rs', 'eg', 'cell', 'signalling', 'phagocyte', 'action', 'well', 'systems', 'cause', 'particular', 'problems', 'eg', 'premature', 'babies', 'eye', 'ear', 'presented', 'acute', 'chronic', 'inflammation', 'used', 'illustrate', 'roles', 'comprehensive', 'description', 'role', 'rs', 'human', 'diseases', 'cancer', 'heart', 'disease', 'dementia', 'ageing', 'process', 'toxicity', 'many', 'agents', 'ethanol', 'carbon', 'tetrachloride', 'paraquat', 'therapeutic', 'agents', 'active', 'rs', 'reviewed', 'detail', 'including', 'nadph', 'oxidase', 'inhibitors', 'nacetylcysteine', 'ebselen', 'global', 'food', 'demand', 'increasing', 'rapidly', 'environmental', 'impacts', 'agricultural', 'expansion', 'project', 'global', 'demand', 'crop', 'production', '2050', 'evaluate', 'environmental', 'impacts', 'alternative', 'ways', 'demand', 'might', 'met', 'find', 'per', 'capita', 'demand', 'crops', 'measured', 'caloric', 'protein', 'content', 'crops', 'combined', 'similarly', 'increasing', 'function', 'per', 'capita', 'real', 'income', 'since', '1960', 'relationship', 'forecasts', '100110', 'increase', 'global', 'crop', 'demand', '2005', '2050', 'quantitative', 'assessments', 'show', 'environmental', 'impacts', 'meeting', 'demand', 'depend', 'global', 'agriculture', 'expands', 'current', 'trends', 'greater', 'agricultural', 'intensification', 'richer', 'nations', 'greater', 'land', 'clearing', 'extensification', 'poorer', 'nations', 'continue', '1', 'billion', 'ha', 'land', 'would', 'cleared', 'globally', '2050', 'co2c', 'equivalent', 'greenhouse', 'gas', 'emissions', 'reaching', '3', 'gt', 'y1', 'n', 'use', '250', 'mt', 'y1', 'contrast', '2050', 'crop', 'demand', 'met', 'moderate', 'intensification', 'focused', 'existing', 'croplands', 'underyielding', 'nations', 'adaptation', 'transfer', 'highyielding', 'technologies', 'croplands', 'global', 'technological', 'improvements', 'analyses', 'forecast', 'land', 'clearing', '02', 'billion', 'ha', 'greenhouse', 'gas', 'emissions', '1', 'gt', 'y1', 'global', 'n', 'use', '225', 'mt', 'y1', 'efficient', 'management', 'practices', 'could', 'substantially', 'lower', 'nitrogen', 'use', 'attainment', 'high', 'yields', 'existing', 'croplands', 'underyielding', 'nations', 'great', 'importance', 'global', 'crop', 'demand', 'met', 'minimal', 'environmental', 'impacts', 'one', 'first', 'specialized', 'agencies', 'united', 'nations', 'become', 'active', 'food', 'agriculture', 'organization', 'elicited', 'interest', 'beyond', 'specialized', 'field', 'agricultural', 'economists', 'attempting', 'solve', 'one', 'basic', 'problems', 'world', 'adequate', 'food', 'supply', 'organization', 'represents', 'significant', 'hopeful', 'international', 'attempt', 'create', 'world', 'may', 'actually', 'exist', 'freedom', 'want', 'objectives', 'fao', 'formally', 'expressed', 'preamble', 'constitution', 'read', 'follows', 'nations', 'accepting', 'constitution', 'determined', 'promote', 'common', 'welfare', 'furthering', 'separate', 'collective', 'action', 'part', 'purpose', 'raising', 'levels', 'nutrition', 'standards', 'living', 'people', 'jurisdiction', 'securing', 'improvements', 'efficiency', 'production', 'food', 'agricultural', 'products', 'bettering', 'conditions', 'rural', 'populations', 'thus', 'contributing', 'toward', 'expanding', 'world', 'economy', 'hereby', 'establish', 'food', 'agriculture', 'organization', 'united', 'nations', 'Artificial', 'Intelligence', '(', 'AI', ')', 'and', 'machine', 'learning', '(', 'ML', ')', 'are', 'becoming', 'increasingly', 'ubiquitous', 'in', 'our', 'everyday', 'lives', '.', 'Despite', 'the', 'rapid', 'pace', 'of', 'these', 'developments', ',', 'debates', 'around', 'responsible', 'AI', 'and', 'AI', 'governance', 'are', 'still', 'maturing', '.', 'This', 'paper', 'outlines', 'the', 'growth', 'of', 'the', 'ethical', 'AI', 'movement', 'internationally', 'and', 'nationally', 'to', 'provide', 'context', 'for', 'the', 'CAIDG', '’', 's', 'Ethics', 'Hub', 'Initiative', '.', 'It', 'touches', 'on', 'open', 'questions', 'in', 'the', 'field', 'and', 'discusses', 'how', 'these', 'questions', 'influenced', 'the', 'trajectory', 'of', 'the', 'Hub', '’', 's', 'research', 'and', 'methodologies', '.', 'The', 'paper', 'reflects', 'on', 'the', 'piloted', 'empirical', 'exercises', 'and', 'charts', 'how', 'research', 'questions', 'developed', 'and', 'changed', 'over', 'time', '.', 'Along', 'the', 'way', ',', 'we', 'identified', 'themes', 'of', 'power', 'and', 'resource', 'differentials', ',', 'as', 'well', 'as', 'communication', 'breakdowns', 'that', 'shaped', 'the', 'latter', 'stages', 'of', 'our', 'project', '.', 'Given', 'the', 'nature', 'of', 'our', 'pilot', 'project', ',', 'our', 'findings', 'are', 'not', 'indicative', 'or', 'generalizable', 'of', 'the', 'entire', 'field', 'in', 'Singapore', '.', 'Nonetheless', ',', 'they', 'represent', 'a', 'meaningful', 'snapshot', 'of', 'how', 'debates', 'around', 'ethical', 'AI', 'and', 'its', 'operationalization', 'are', 'unfolding', 'in', 'Singapore', 'and', 'beyond', '.', 'Ultimately', ',', 'we', 'encourage', 'more', 'focused', 'research', 'on', 'the', 'development', 'and', 'design', 'of', 'institutional', 'incentive', 'mechanisms', 'to', 'foster', 'greater', 'cohesion', 'around', 'responsible', 'AI', 'development', 'and', 'deployment', 'norms', '.', 'Automatic', 'Facial', 'Expression', 'Recognition', 'systems', 'have', 'come', 'a', 'long', 'way', 'since', 'the', 'earliest', 'approaches', 'in', 'the', 'early', '1970s', '.', 'We', 'are', 'now', 'at', 'a', 'point', 'where', 'the', 'earliest', 'systems', 'are', 'commercially', 'applied', ',', 'most', 'notably', 'the', 'smile', 'detectors', 'in', 'digital', 'cameras', '.', 'But', 'although', 'facial', 'expression', 'recognition', 'is', 'maturing', 'as', 'a', 'research', 'field', ',', 'it', 'is', 'far', 'from', 'finished', '.', 'New', 'techniques', 'continue', 'to', 'be', 'developed', 'on', 'all', 'aspects', 'of', 'the', 'processing', 'pipeline', ':', 'from', 'face', 'detection', ',', 'via', 'feature', 'extraction', 'to', 'machine', 'learning', '.', 'Nor', 'is', 'the', 'field', 'blind', 'to', 'the', 'progress', 'made', 'in', 'the', 'social', 'sciences', 'with', 'respect', 'to', 'emotion', 'theory', '.', 'Gone', 'are', 'the', 'days', 'that', 'people', 'only', 'tried', 'to', 'detect', 'six', 'discrete', 'expressions', 'that', 'were', 'turned-on', 'or', 'off', 'like', 'the', 'switching', 'of', 'lights', '.', 'The', 'theory', 'of', 'Social', 'Signal', 'Processing', 'now', 'complements', 'classical', 'emotion', 'theory', ',', 'and', 'modern', 'approaches', 'dissect', 'an', 'expression', 'into', 'its', 'temporal', 'phases', ',', 'analyse', 'intensity', ',', 'symmetry', ',', 'micro-expressions', 'and', 'dynamic', 'differences', 'between', 'morphologically', 'similar', 'expressions', '.', 'Brave', 'new', 'worlds', 'are', 'opened', 'up—Automatic', 'Facial', 'Expression', 'Analysis', 'is', 'poised', 'to', 'revolutionalise', 'medicine', 'with', 'the', 'advent', 'of', 'behaviomedics', ',', 'gaming', 'with', 'enriched', 'player–non-player', 'interactions', ',', 'teleconference', 'meetings', 'with', 'automatic', 'trust', 'and', 'engagement', 'analysis', ',', 'and', 'human–robot', 'interaction', 'with', 'robots', 'displaying', 'actual', 'empathy', '.', 'With', 'this', 'volume', 'I', 'complete', 'my', 'four-year', 'term', 'as', 'executive', 'editor', 'of', 'Machine', 'Learning', ',', 'and', 'Tom', 'Dietterich', ',', 'who', 'has', 'been', 'co-executive', 'editor', 'with', 'me', 'recently', ',', 'takes', 'over', 'the', 'helm', '--', 'or', 'starts', 'serving', 'his', 'sentence', ',', 'depending', 'upon', 'one', \"'s\", 'point', 'of', 'view', '.', 'Let', 'me', 'take', 'this', 'opportunity', 'to', 'make', 'a', 'few', 'reflections', 'about', 'the', 'state', 'of', 'the', 'field', ';', 'past', ',', 'present', 'and', 'future', ',', 'based', 'on', 'personal', 'observations', '.', 'A', 'decade', 'ago', 'machine', 'learning', 'was', 'regrouping', 'from', 'the', 'rather', 'uneventful', '1970s', '.', 'The', 'first', 'machine', 'learning', 'workshop', 'was', 'held', 'in', '1980', 'at', 'Carnegie', 'Mellon', 'University', 'with', 'some', 'two', 'dozen', 'participants', 'and', 'photocopied', 'preprints', '.', 'Shortly', 'thereafter', 'we', 'started', 'preparing', 'the', 'first', 'machine', 'learning', 'book', ',', 'and', 'I', 'was', 'in', 'charge', 'of', 'finding', 'a', 'publication', 'venue', '.', 'However', 'the', 'title', '``', 'Machine', 'Learning', \"''\", 'raised', 'skeptical', 'eyebrows', 'in', 'publishers', '.', 'By', '``', 'machine', 'learning', \"''\", 'did', 'we', 'not', 'really', 'mean', 'learning', 'about', 'machines', 'rather', 'than', 'learning', 'by', 'machines', '?', 'Could', \"n't\", 'we', 'think', 'of', 'something', 'more', 'scientific-sounding', 'to', 'call', 'the', 'book', '?', 'And', 'anyway', 'had', \"n't\", 'Minsky', 'and', 'Papert', 'debunked', 'this', 'learning', 'nonsense', '?', 'Since', 'it', 'proved', 'difficult', 'to', 'explain', 'the', 'difference', 'between', 'linear', 'perceptrons', 'and', 'symbolic', 'learning', 'to', 'those', 'publishers', '(', 'who', 'shall', 'go', 'unnamed', ',', 'to', 'protect', 'the', 'guilty', ')', ',', 'we', 'approached', 'Nils', 'Nilsson', 'and', 'his', 'Tioga', 'Press', '.', 'Nils', 'embraced', 'the', 'project', 'with', 'foresight', 'and', 'enthusiasm', ',', 'and', 'the', 'rest', ',', 'as', 'they', 'say', 'in', 'the', 'tired', 'cliche', ',', 'is', 'history', '.', 'Most', 'existing', 'Augmented', 'Reality', '(', 'AR', ')', 'and', 'Mixed', 'Reality', '(', 'MR', ')', 'systems', 'are', 'able', 'to', 'understand', 'the', '3D', 'geometry', 'of', 'the', 'surroundings', 'but', 'lack', 'the', 'ability', 'to', 'detect', 'and', 'classify', 'complex', 'objects', 'in', 'the', 'real', 'world', '.', 'Such', 'capabilities', 'can', 'be', 'enabled', 'with', 'deep', 'Convolutional', 'Neural', 'Networks', '(', 'CNN', ')', ',', 'but', 'it', 'remains', 'difficult', 'to', 'execute', 'large', 'networks', 'on', 'mobile', 'devices', '.', 'Offloading', 'object', 'detection', 'to', 'the', 'edge', 'or', 'cloud', 'is', 'also', 'very', 'challenging', 'due', 'to', 'the', 'stringent', 'requirements', 'on', 'high', 'detection', 'accuracy', 'and', 'low', 'end-to-end', 'latency', '.', 'The', 'long', 'latency', 'of', 'existing', 'offloading', 'techniques', 'can', 'significantly', 'reduce', 'the', 'detection', 'accuracy', 'due', 'to', 'changes', 'in', 'the', 'user', \"'s\", 'view', '.', 'To', 'address', 'the', 'problem', ',', 'we', 'design', 'a', 'system', 'that', 'enables', 'high', 'accuracy', 'object', 'detection', 'for', 'commodity', 'AR/MR', 'system', 'running', 'at', '60fps', '.', 'The', 'system', 'employs', 'low', 'latency', 'offloading', 'techniques', ',', 'decouples', 'the', 'rendering', 'pipeline', 'from', 'the', 'offloading', 'pipeline', ',', 'and', 'uses', 'a', 'fast', 'object', 'tracking', 'method', 'to', 'maintain', 'detection', 'accuracy', '.', 'The', 'result', 'shows', 'that', 'the', 'system', 'can', 'improve', 'the', 'detection', 'accuracy', 'by', '20.2', '%', '-34.8', '%', 'for', 'the', 'object', 'detection', 'and', 'human', 'keypoint', 'detection', 'tasks', ',', 'and', 'only', 'requires', '2.24ms', 'latency', 'for', 'object', 'tracking', 'on', 'the', 'AR', 'device', '.', 'Thus', ',', 'the', 'system', 'leaves', 'more', 'time', 'and', 'computational', 'resources', 'to', 'render', 'virtual', 'elements', 'for', 'the', 'next', 'frame', 'and', 'enables', 'higher', 'quality', 'AR/MR', 'experiences', '.', 'We', 'present', 'YOLO', ',', 'a', 'new', 'approach', 'to', 'object', 'detection', '.', 'Prior', 'work', 'on', 'object', 'detection', 'repurposes', 'classifiers', 'to', 'perform', 'detection', '.', 'Instead', ',', 'we', 'frame', 'object', 'detection', 'as', 'a', 'regression', 'problem', 'to', 'spatially', 'separated', 'bounding', 'boxes', 'and', 'associated', 'class', 'probabilities', '.', 'A', 'single', 'neural', 'network', 'predicts', 'bounding', 'boxes', 'and', 'class', 'probabilities', 'directly', 'from', 'full', 'images', 'in', 'one', 'evaluation', '.', 'Since', 'the', 'whole', 'detection', 'pipeline', 'is', 'a', 'single', 'network', ',', 'it', 'can', 'be', 'optimized', 'end-to-end', 'directly', 'on', 'detection', 'performance', '.', 'Our', 'unified', 'architecture', 'is', 'extremely', 'fast', '.', 'Our', 'base', 'YOLO', 'model', 'processes', 'images', 'in', 'real-time', 'at', '45', 'frames', 'per', 'second', '.', 'A', 'smaller', 'version', 'of', 'the', 'network', ',', 'Fast', 'YOLO', ',', 'processes', 'an', 'astounding', '155', 'frames', 'per', 'second', 'while', 'still', 'achieving', 'double', 'the', 'mAP', 'of', 'other', 'real-time', 'detectors', '.', 'Compared', 'to', 'state-of-the-art', 'detection', 'systems', ',', 'YOLO', 'makes', 'more', 'localization', 'errors', 'but', 'is', 'less', 'likely', 'to', 'predict', 'false', 'positives', 'on', 'background', '.', 'Finally', ',', 'YOLO', 'learns', 'very', 'general', 'representations', 'of', 'objects', '.', 'It', 'outperforms', 'other', 'detection', 'methods', ',', 'including', 'DPM', 'and', 'R-CNN', ',', 'when', 'generalizing', 'from', 'natural', 'images', 'to', 'other', 'domains', 'like', 'artwork', '.', 'Deep', 'learning', 'allows', 'computational', 'models', 'that', 'are', 'composed', 'of', 'multiple', 'processing', 'layers', 'to', 'learn', 'representations', 'of', 'data', 'with', 'multiple', 'levels', 'of', 'abstraction', '.', 'These', 'methods', 'have', 'dramatically', 'improved', 'the', 'state-of-the-art', 'in', 'speech', 'recognition', ',', 'visual', 'object', 'recognition', ',', 'object', 'detection', 'and', 'many', 'other', 'domains', 'such', 'as', 'drug', 'discovery', 'and', 'genomics', '.', 'Deep', 'learning', 'discovers', 'intricate', 'structure', 'in', 'large', 'data', 'sets', 'by', 'using', 'the', 'backpropagation', 'algorithm', 'to', 'indicate', 'how', 'a', 'machine', 'should', 'change', 'its', 'internal', 'parameters', 'that', 'are', 'used', 'to', 'compute', 'the', 'representation', 'in', 'each', 'layer', 'from', 'the', 'representation', 'in', 'the', 'previous', 'layer', '.', 'Deep', 'convolutional', 'nets', 'have', 'brought', 'about', 'breakthroughs', 'in', 'processing', 'images', ',', 'video', ',', 'speech', 'and', 'audio', ',', 'whereas', 'recurrent', 'nets', 'have', 'shone', 'light', 'on', 'sequential', 'data', 'such', 'as', 'text', 'and', 'speech', '.', 'Deep', 'convolutional', 'neural', 'networks', 'have', 'performed', 'remarkably', 'well', 'on', 'many', 'Computer', 'Vision', 'tasks', '.', 'However', ',', 'these', 'networks', 'are', 'heavily', 'reliant', 'on', 'big', 'data', 'to', 'avoid', 'overfitting', '.', 'Overfitting', 'refers', 'to', 'the', 'phenomenon', 'when', 'a', 'network', 'learns', 'a', 'function', 'with', 'very', 'high', 'variance', 'such', 'as', 'to', 'perfectly', 'model', 'the', 'training', 'data', '.', 'Unfortunately', ',', 'many', 'application', 'domains', 'do', 'not', 'have', 'access', 'to', 'big', 'data', ',', 'such', 'as', 'medical', 'image', 'analysis', '.', 'This', 'survey', 'focuses', 'on', 'Data', 'Augmentation', ',', 'a', 'data-space', 'solution', 'to', 'the', 'problem', 'of', 'limited', 'data', '.', 'Data', 'Augmentation', 'encompasses', 'a', 'suite', 'of', 'techniques', 'that', 'enhance', 'the', 'size', 'and', 'quality', 'of', 'training', 'datasets', 'such', 'that', 'better', 'Deep', 'Learning', 'models', 'can', 'be', 'built', 'using', 'them', '.', 'The', 'image', 'augmentation', 'algorithms', 'discussed', 'in', 'this', 'survey', 'include', 'geometric', 'transformations', ',', 'color', 'space', 'augmentations', ',', 'kernel', 'filters', ',', 'mixing', 'images', ',', 'random', 'erasing', ',', 'feature', 'space', 'augmentation', ',', 'adversarial', 'training', ',', 'generative', 'adversarial', 'networks', ',', 'neural', 'style', 'transfer', ',', 'and', 'meta-learning', '.', 'The', 'application', 'of', 'augmentation', 'methods', 'based', 'on', 'GANs', 'are', 'heavily', 'covered', 'in', 'this', 'survey', '.', 'In', 'addition', 'to', 'augmentation', 'techniques', ',', 'this', 'paper', 'will', 'briefly', 'discuss', 'other', 'characteristics', 'of', 'Data', 'Augmentation', 'such', 'as', 'test-time', 'augmentation', ',', 'resolution', 'impact', ',', 'final', 'dataset', 'size', ',', 'and', 'curriculum', 'learning', '.', 'This', 'survey', 'will', 'present', 'existing', 'methods', 'for', 'Data', 'Augmentation', ',', 'promising', 'developments', ',', 'and', 'meta-level', 'decisions', 'for', 'implementing', 'Data', 'Augmentation', '.', 'Readers', 'will', 'understand', 'how', 'Data', 'Augmentation', 'can', 'improve', 'the', 'performance', 'of', 'their', 'models', 'and', 'expand', 'limited', 'datasets', 'to', 'take', 'advantage', 'of', 'the', 'capabilities', 'of', 'big', 'data', '.', 'Recent', 'work', 'has', 'demonstrated', 'that', 'deep', 'neural', 'networks', 'are', 'vulnerable', 'to', 'adversarial', 'examples', '--', '-inputs', 'that', 'are', 'almost', 'indistinguishable', 'from', 'natural', 'data', 'and', 'yet', 'classified', 'incorrectly', 'by', 'the', 'network', '.', 'In', 'fact', ',', 'some', 'of', 'the', 'latest', 'findings', 'suggest', 'that', 'the', 'existence', 'of', 'adversarial', 'attacks', 'may', 'be', 'an', 'inherent', 'weakness', 'of', 'deep', 'learning', 'models', '.', 'To', 'address', 'this', 'problem', ',', 'we', 'study', 'the', 'adversarial', 'robustness', 'of', 'neural', 'networks', 'through', 'the', 'lens', 'of', 'robust', 'optimization', '.', 'This', 'approach', 'provides', 'us', 'with', 'a', 'broad', 'and', 'unifying', 'view', 'on', 'much', 'of', 'the', 'prior', 'work', 'on', 'this', 'topic', '.', 'Its', 'principled', 'nature', 'also', 'enables', 'us', 'to', 'identify', 'methods', 'for', 'both', 'training', 'and', 'attacking', 'neural', 'networks', 'that', 'are', 'reliable', 'and', ',', 'in', 'a', 'certain', 'sense', ',', 'universal', '.', 'In', 'particular', ',', 'they', 'specify', 'a', 'concrete', 'security', 'guarantee', 'that', 'would', 'protect', 'against', 'any', 'adversary', '.', 'These', 'methods', 'let', 'us', 'train', 'networks', 'with', 'significantly', 'improved', 'resistance', 'to', 'a', 'wide', 'range', 'of', 'adversarial', 'attacks', '.', 'They', 'also', 'suggest', 'the', 'notion', 'of', 'security', 'against', 'a', 'first-order', 'adversary', 'as', 'a', 'natural', 'and', 'broad', 'security', 'guarantee', '.', 'We', 'believe', 'that', 'robustness', 'against', 'such', 'well-defined', 'classes', 'of', 'adversaries', 'is', 'an', 'important', 'stepping', 'stone', 'towards', 'fully', 'resistant', 'deep', 'learning', 'models', '.', 'Code', 'and', 'pre-trained', 'models', 'are', 'available', 'at', 'this', 'https', 'URL', 'and', 'this', 'https', 'URL', '.', 'While', 'the', 'Transformer', 'architecture', 'has', 'become', 'the', 'de-facto', 'standard', 'for', 'natural', 'language', 'processing', 'tasks', ',', 'its', 'applications', 'to', 'computer', 'vision', 'remain', 'limited', '.', 'In', 'vision', ',', 'attention', 'is', 'either', 'applied', 'in', 'conjunction', 'with', 'convolutional', 'networks', ',', 'or', 'used', 'to', 'replace', 'certain', 'components', 'of', 'convolutional', 'networks', 'while', 'keeping', 'their', 'overall', 'structure', 'in', 'place', '.', 'We', 'show', 'that', 'this', 'reliance', 'on', 'CNNs', 'is', 'not', 'necessary', 'and', 'a', 'pure', 'transformer', 'applied', 'directly', 'to', 'sequences', 'of', 'image', 'patches', 'can', 'perform', 'very', 'well', 'on', 'image', 'classification', 'tasks', '.', 'When', 'pre-trained', 'on', 'large', 'amounts', 'of', 'data', 'and', 'transferred', 'to', 'multiple', 'mid-sized', 'or', 'small', 'image', 'recognition', 'benchmarks', '(', 'ImageNet', ',', 'CIFAR-100', ',', 'VTAB', ',', 'etc', '.', ')', ',', 'Vision', 'Transformer', '(', 'ViT', ')', 'attains', 'excellent', 'results', 'compared', 'to', 'state-of-the-art', 'convolutional', 'networks', 'while', 'requiring', 'substantially', 'fewer', 'computational', 'resources', 'to', 'train', '.', '``', 'Excerpted', 'from', '``', \"''\", 'Glimpse', ':', 'Continuous', ',', 'Real-Time', 'Object', 'Recognition', 'on', 'Mobile', 'Devices', \"''\", \"''\", 'from', 'Proceedings', 'of', 'the', '13th', 'ACM', 'Conference', 'on', 'Embedded', 'Networked', 'Sensor', 'Systems', 'with', 'permission', '.', 'http', ':', '//dx.doi.org/10.1145/2809695.2809711', '©', 'ACM', '2015', '.', 'Glimpse', 'is', 'a', 'continuous', ',', 'real-time', 'object', 'recognition', 'system', 'for', 'camera-equipped', 'mobile', 'devices', '.', 'Glimpse', 'captures', 'full-motion', 'video', ',', 'locates', 'objects', 'of', 'interest', ',', 'recognizes', 'and', 'labels', 'them', ',', 'and', 'tracks', 'them', 'from', 'frame', 'to', 'frame', 'for', 'the', 'user', '.', 'Because', 'the', 'algorithms', 'for', 'object', 'recognition', 'entail', 'significant', 'computation', ',', 'Glimpse', 'runs', 'them', 'on', 'server', 'machines', '.', 'When', 'the', 'latency', 'between', 'the', 'server', 'and', 'mobile', 'device', 'is', 'higher', 'than', 'a', 'frame-time', ',', 'this', 'approach', 'lowers', 'object', 'recognition', 'accuracy', '.', 'To', 'regain', 'accuracy', ',', 'Glimpse', 'uses', 'an', 'active', 'cache', 'of', 'video', 'frames', 'on', 'the', 'mobile', 'device', '.', 'A', 'subset', 'of', 'the', 'frames', 'in', 'the', 'active', 'cache', 'are', 'used', 'to', 'track', 'objects', 'on', 'the', 'mobile', ',', 'using', '(', 'stale', ')', 'hints', 'about', 'objects', 'that', 'arrive', 'from', 'the', 'server', 'from', 'time', 'to', 'time', '.', 'To', 'reduce', 'network', 'bandwidth', 'usage', ',', 'Glimpse', 'computes', 'trigger', 'frames', 'to', 'send', 'to', 'the', 'server', 'for', 'recognizing', '.', \"''\", 'As', 'healthcare', 'costs', 'rise', 'in', 'the', 'United', 'States', ',', 'debate', 'is', 'ongoing', 'over', 'how', 'to', 'obtain', 'better', 'value', 'for', 'dollars', 'spent', '.', 'In', 'this', 'context', ',', 'the', 'use', 'of', 'cost-effectiveness', 'analysis', '(', 'CEA', ')', 'is', 'more', 'compelling', 'than', 'ever', '.', 'This', 'book', ',', 'written', 'by', 'the', 'Second', 'Panel', 'on', 'Cost-Effectiveness', 'in', 'Health', 'and', 'Medicine', ',', 'reviews', 'key', 'concepts', 'and', 'analytic', 'challenges', 'in', 'CEA', '.', 'The', 'authors', 'endorse', 'the', 'original', 'Panel', '’', 's', 'concept', 'of', 'a', 'reference', 'case', 'and', 'support', 'its', 'recommendation', 'that', 'analysts', 'take', 'a', 'broad', 'societal', 'perspective', ';', 'in', 'addition', ',', 'they', 'recommend', 'a', 'healthcare', 'sector', 'perspective', 'for', 'a', 'second', 'reference', 'case', ',', 'as', 'well', 'as', 'an', 'important', 'new', 'framework', ',', 'the', 'Impact', 'Inventory', ',', 'for', 'detailing', 'costs', 'and', 'effects', '.', 'The', 'revisions', 'draw', 'on', 'advances', 'in', 'the', 'field', 'and', 'include', 'three', 'new', 'chapters', 'that', 'capture', 'research', 'on', 'decision', 'modeling', ',', 'methods', 'for', 'evidence', 'synthesis', ',', 'and', 'ethical', 'considerations', '.', 'The', 'volume', 'also', 'includes', 'two', 'new', 'worked', 'examples', '(', 'Appendix', 'A', 'and', 'Appendix', 'B', ')', 'to', 'illustrate', 'ways', 'to', 'implement', 'the', 'authors', '’', 'recommendations', '.', 'This', 'abstract', 'delves', 'into', 'a', 'conceptual', 'framework', 'that', 'envisions', 'clinicians', 'not', 'only', 'as', 'caregivers', 'at', 'the', 'bedside', 'but', 'as', 'pivotal', 'guardians', 'of', 'public', 'health', ',', 'medicine', ',', 'and', 'science', '.', 'The', 'traditional', 'role', 'of', 'clinicians', 'has', 'predominantly', 'centered', 'on', 'individual', 'patient', 'care', ',', 'yet', 'this', 'paradigm', 'proposes', 'an', 'expansion', 'of', 'their', 'responsibilities', 'to', 'encompass', 'broader', 'societal', 'well-being', '.', 'By', 'exploring', 'the', 'intersections', 'of', 'clinical', 'practice', ',', 'public', 'health', 'initiatives', ',', 'and', 'scientific', 'advancements', ',', 'this', 'paradigm', 'shift', 'aims', 'to', 'harness', 'the', 'expertise', 'and', 'influence', 'of', 'clinicians', 'to', 'address', 'systemic', 'health', 'challenges', '.', 'The', 'proposed', 'framework', 'emphasizes', 'the', 'multifaceted', 'roles', 'clinicians', 'can', 'play', 'in', 'shaping', 'public', 'health', 'policies', ',', 'advancing', 'medical', 'research', ',', 'and', 'fostering', 'a', 'culture', 'of', 'evidence-based', 'practice', '.', 'Drawing', 'on', 'case', 'studies', 'and', 'theoretical', 'models', ',', 'this', 'abstract', 'highlights', 'the', 'potential', 'impact', 'of', 'empowering', 'clinicians', 'to', 'contribute', 'actively', 'to', 'public', 'health', 'discourse', ',', 'policy', 'formulation', ',', 'and', 'community', 'education', '.', 'It', 'underscores', 'the', 'importance', 'of', 'integrating', 'clinical', 'knowledge', 'with', 'scientific', 'inquiry', ',', 'thereby', 'fostering', 'a', 'more', 'comprehensive', 'approach', 'to', 'healthcare', 'that', 'transcends', 'the', 'confines', 'of', 'individual', 'patient', 'interactions', '.', 'The', 'new', 'edition', 'of', 'this', 'well-established', 'book', 'is', 'thoroughly', 'revised', 'and', 'gives', 'a', 'comprehensive', 'account', 'of', 'the', 'role', 'of', 'free', 'radicals', ',', 'other', 'reactive', 'species', '(', 'RS', ')', ',', 'and', 'antioxidants', 'in', 'life', ',', 'health', ',', 'and', 'disease', '.', 'Chapter', '1', 'reviews', 'how', 'oxygen', '(', 'O2', ')', 'is', 'used', 'by', 'living', 'organisms', ',', 'why', 'it', 'can', 'be', 'toxic', ',', 'and', 'introduces', 'the', 'concept', 'of', 'oxygen', 'radicals', 'and', 'other', 'RS', ';', 'their', 'chemistry', 'is', 'detailed', 'in', 'Chapter', '2', ',', 'especially', 'for', 'superoxide', ',', 'hydroxyl', 'radical', '(', 'including', 'Fenton', 'chemistry', ')', ',', 'peroxynitrite', ',', 'nitric', 'oxide', ',', 'ozone', ',', 'and', 'singlet', 'O2', ',', 'with', 'emphasis', 'on', 'their', 'redox', 'properties', '.', 'Subsequent', 'chapters', 'detail', 'what', 'antioxidants', 'can', 'be', 'made', 'in', 'vivo', '(', 'e.g', '.', 'superoxide', 'dismutases', ',', 'peroxiredoxins', ')', 'and', 'which', 'can', 'come', 'from', 'diet', '(', 'e.g', '.', 'vitamins', 'E', 'and', 'C', ',', 'carotenoids', ',', 'and', 'polyphenols', 'such', 'as', 'the', 'flavonoids', ')', 'and', 'how', 'they', 'work', 'in', 'vivo', '.', 'The', 'role', 'of', 'RS', 'in', 'cell', 'proliferation', ',', 'senescence', ',', 'and', 'death', '(', 'e.g', '.', 'by', 'apoptosis', ',', 'necrosis', ',', 'or', 'intermediate', 'forms', ')', 'is', 'presented', '.', 'Methods', 'for', 'measuring', 'RS', 'are', 'described', 'in', 'detail', ',', 'including', 'electron', 'paramagnetic', 'resonance', 'and', 'biomarker', 'determination', '.', 'Useful', 'roles', 'for', 'RS', '(', 'e.g', '.', 'cell', 'signalling', ',', 'phagocyte', 'action', ')', ',', 'as', 'well', 'as', 'systems', 'in', 'which', 'they', 'cause', 'particular', 'problems', '(', 'e.g', '.', 'premature', 'babies', ',', 'the', 'eye', ',', 'the', 'ear', ')', 'are', 'presented', '.', 'Acute', 'and', 'chronic', 'inflammation', 'are', 'used', 'to', 'illustrate', 'both', 'roles', 'There', 'is', 'a', 'comprehensive', 'description', 'of', 'the', 'role', 'of', 'RS', 'in', 'human', 'diseases', ',', 'from', 'cancer', 'to', 'heart', 'disease', 'to', 'dementia', ',', 'in', 'the', 'ageing', 'process', ',', 'and', 'in', 'the', 'toxicity', 'of', 'many', 'agents', ',', 'from', 'ethanol', 'to', 'carbon', 'tetrachloride', 'to', 'paraquat', '.', 'Therapeutic', 'agents', 'active', 'against', 'RS', 'are', 'reviewed', 'in', 'detail', ',', 'including', 'NADPH', 'oxidase', 'inhibitors', ',', 'N-acetylcysteine', ',', 'and', 'Ebselen', '.', 'Global', 'food', 'demand', 'is', 'increasing', 'rapidly', ',', 'as', 'are', 'the', 'environmental', 'impacts', 'of', 'agricultural', 'expansion', '.', 'Here', ',', 'we', 'project', 'global', 'demand', 'for', 'crop', 'production', 'in', '2050', 'and', 'evaluate', 'the', 'environmental', 'impacts', 'of', 'alternative', 'ways', 'that', 'this', 'demand', 'might', 'be', 'met', '.', 'We', 'find', 'that', 'per', 'capita', 'demand', 'for', 'crops', ',', 'when', 'measured', 'as', 'caloric', 'or', 'protein', 'content', 'of', 'all', 'crops', 'combined', ',', 'has', 'been', 'a', 'similarly', 'increasing', 'function', 'of', 'per', 'capita', 'real', 'income', 'since', '1960', '.', 'This', 'relationship', 'forecasts', 'a', '100-110', '%', 'increase', 'in', 'global', 'crop', 'demand', 'from', '2005', 'to', '2050', '.', 'Quantitative', 'assessments', 'show', 'that', 'the', 'environmental', 'impacts', 'of', 'meeting', 'this', 'demand', 'depend', 'on', 'how', 'global', 'agriculture', 'expands', '.', 'If', 'current', 'trends', 'of', 'greater', 'agricultural', 'intensification', 'in', 'richer', 'nations', 'and', 'greater', 'land', 'clearing', '(', 'extensification', ')', 'in', 'poorer', 'nations', 'were', 'to', 'continue', ',', '~1', 'billion', 'ha', 'of', 'land', 'would', 'be', 'cleared', 'globally', 'by', '2050', ',', 'with', 'CO', '(', '2', ')', '-C', 'equivalent', 'greenhouse', 'gas', 'emissions', 'reaching', '~3', 'Gt', 'y', '(', '-1', ')', 'and', 'N', 'use', '~250', 'Mt', 'y', '(', '-1', ')', 'by', 'then', '.', 'In', 'contrast', ',', 'if', '2050', 'crop', 'demand', 'was', 'met', 'by', 'moderate', 'intensification', 'focused', 'on', 'existing', 'croplands', 'of', 'underyielding', 'nations', ',', 'adaptation', 'and', 'transfer', 'of', 'high-yielding', 'technologies', 'to', 'these', 'croplands', ',', 'and', 'global', 'technological', 'improvements', ',', 'our', 'analyses', 'forecast', 'land', 'clearing', 'of', 'only', '~0.2', 'billion', 'ha', ',', 'greenhouse', 'gas', 'emissions', 'of', '~1', 'Gt', 'y', '(', '-1', ')', ',', 'and', 'global', 'N', 'use', 'of', '~225', 'Mt', 'y', '(', '-1', ')', '.', 'Efficient', 'management', 'practices', 'could', 'substantially', 'lower', 'nitrogen', 'use', '.', 'Attainment', 'of', 'high', 'yields', 'on', 'existing', 'croplands', 'of', 'underyielding', 'nations', 'is', 'of', 'great', 'importance', 'if', 'global', 'crop', 'demand', 'is', 'to', 'be', 'met', 'with', 'minimal', 'environmental', 'impacts', '.', 'One', 'of', 'the', 'first', 'of', 'the', 'specialized', 'agencies', 'of', 'the', 'United', 'Nations', 'to', 'become', 'active', ',', 'the', 'Food', 'and', 'Agriculture', 'Organization', 'has', 'elicited', 'interest', 'beyond', 'the', 'specialized', 'field', 'of', 'agricultural', 'economists', '.', 'Attempting', 'as', 'it', 'does', 'to', 'solve', 'one', 'of', 'the', 'very', 'basic', 'problems', 'of', 'the', 'world', ',', 'that', 'of', 'an', 'adequate', 'food', 'supply', ',', 'the', 'organization', 'represents', 'a', 'significant', 'and', 'hopeful', 'international', 'attempt', 'to', 'create', 'a', 'world', 'in', 'which', 'there', 'may', 'actually', 'exist', '“', 'freedom', 'from', 'want.', '”', 'The', 'objectives', 'of', 'FAO', ',', 'as', 'formally', 'expressed', 'in', 'the', 'preamble', 'to', 'the', 'constitution', ',', 'read', 'as', 'follows', ':', '“', 'The', 'nations', 'accepting', 'this', 'constitution', 'being', 'determined', 'to', 'promote', 'the', 'common', 'welfare', 'by', 'furthering', 'separate', 'and', 'collective', 'action', 'on', 'their', 'part', 'for', 'the', 'purpose', 'of', 'raising', 'levels', 'of', 'nutrition', 'and', 'standards', 'of', 'living', 'of', 'the', 'people', 'under', 'their', 'jurisdiction', ',', 'securing', 'improvements', 'in', 'the', 'efficiency', 'of', 'the', 'production', 'of', 'all', 'food', 'and', 'agricultural', 'products', ',', 'bettering', 'the', 'conditions', 'of', 'rural', 'populations', ',', 'and', 'thus', 'contributing', 'toward', 'an', 'expanding', 'world', 'economy', ',', 'hereby', 'establish', 'the', 'Food', 'and', 'Agriculture', 'Organization', 'of', 'the', 'United', 'Nations', '.', 'communicating', 'ethics', 'across', 'ai', 'ecosystem', 'automatic', 'facial', 'expression', 'analysis', 'machine', 'learning', 'maturing', 'field', 'edge', 'assisted', 'realtime', 'object', 'detection', 'mobile', 'augmented', 'reality', 'look', 'unified', 'realtime', 'object', 'detection', 'deep', 'learning', 'survey', 'image', 'data', 'augmentation', 'deep', 'learning', 'towards', 'deep', 'learning', 'models', 'resistant', 'adversarial', 'attacks', 'image', 'worth', '16x16', 'words', 'transformers', 'image', 'recognition', 'scale', 'glimpse', 'continuous', 'realtime', 'object', 'recognition', 'mobile', 'devices', 'costeffectiveness', 'health', 'medicine', '2nd', 'edn', 'beyond', 'bedside', 'clinicians', 'guardians', 'public', 'health', 'medicine', 'science', 'free', 'radicals', 'biology', 'medicine', '5th', 'edn', 'global', 'food', 'demand', 'sustainable', 'intensification', 'agriculture', 'food', 'agriculture', 'organization', 'united', 'nations', 'Communicating', 'Ethics', 'across', 'the', 'AI', 'Ecosystem', 'Automatic', 'Facial', 'Expression', 'Analysis', 'Machine', 'Learning', ':', 'A', 'maturing', 'field', 'Edge', 'Assisted', 'Real-Time', 'Object', 'Detection', 'for', 'Mobile', 'and', 'augmented', 'Reality', 'You', 'Only', 'Look', 'Once', ':', 'Unified', ',', 'Real-Time', 'Object', 'Detection', 'Deep', 'learning', 'A', 'survey', 'on', 'Image', 'Data', 'Augmentation', 'for', 'Deep', 'Learning', 'Towards', 'Deep', 'Learning', 'Models', 'Resistant', 'to', 'Adversarial', 'Attacks', 'An', 'Image', 'is', 'Worth', '16x16', 'Words', ':', 'Transformers', 'for', 'Image', 'Recognition', 'at', 'Scale', 'GLIMPSE', ':', 'Continuous', ',', 'Real-Time', 'Object', 'Recognition', 'on', 'Mobile', 'Devices', 'Cost-Effectiveness', 'in', 'Health', 'and', 'Medicine', '(', '2nd', 'edn', ')', 'Beyond', 'the', 'bedside', ':', 'Clinicians', 'as', 'guardians', 'of', 'public', 'health', ',', 'medicine', 'and', 'science', 'Free', 'Radicals', 'in', 'Biology', 'and', 'Medicine', '(', '5th', 'edn', ')', 'Global', 'food', 'demand', 'and', 'the', 'sustainable', 'intensification', 'of', 'agriculture', 'The', 'Food', 'and', 'Agriculture', 'Organization', 'of', 'the', 'United', 'Nations', 'ethical', 'ai', 'responsible', 'ai', 'responsible', 'innovation', 'face', 'detection', 'facial', 'expressions', 'signal', 'processingautomatic', 'analysis', 'machine', 'learning', 'ai', 'bot', 'vr', 'ar', 'ai', 'machine', 'learning', 'machine', 'learning', 'deep', 'learning', 'object', 'detectionmachine', 'learning', 'deep', 'learning', 'object', 'detection', 'deep', 'learning', 'machine', 'learning', 'neural', 'network', 'ai', 'machine', 'learning', 'dcnn', 'machine', 'learning', 'statml', 'machine', 'learning', 'cslg', 'neural', 'evolutionary', 'computing', 'csne', 'computer', 'vision', 'pattern', 'recognition', 'cscv', 'artificial', 'intelligence', 'csai', 'machine', 'learning', 'cslg', 'objectdetectionmachine', 'learning', 'deep', 'learning', 'costeffectiveness', 'analysis', 'reference', 'case', 'healthcare', 'perspective', 'societal', 'perspective', 'impact', 'inventory', 'recommendations', 'health', 'medicine', 'biology', 'science', 'antioxidant', 'cancer', 'dementia', 'free', 'radicals', 'heart', 'disease', 'oxygen', 'radical', 'reactive', 'species', 'superoxide', 'dismutase', 'vitamin', 'e', 'vitamin', 'c', 'foodagricultureglobalization', 'sustainable', 'food', 'agriculte', 'ethical', 'AI', ',', 'responsible', 'AI', ',', 'responsible', 'innovation', 'Face', 'detection', ',', 'Facial', 'expressions', ',', 'Signal', 'processing', ',', 'Automatic', 'analysis', 'machine', 'learning', ',', 'AI', ',', 'bot', 'VR', ',', 'AR', ',', 'AI', ',', 'Machine', 'Learning', 'machine', 'learning', ',', 'Deep', 'Learning', ',', 'Object', 'Detectionmachine', 'learning', ',', 'Deep', 'Learning', ',', 'Object', 'Detection', 'Deep', 'Learning', ',', 'Machine', 'Learning', 'Neural', 'Network', ',', 'AI', ',', 'Machine', 'Learning', ',', 'DCNN', 'Machine', 'Learning', '(', 'stat.ML', ')', ';', 'Machine', 'Learning', '(', 'cs.LG', ')', ';', 'Neural', 'and', 'Evolutionary', 'Computing', '(', 'cs.NE', ')', '``', 'Computer', 'Vision', 'and', 'Pattern', 'Recognition', '(', 'cs.CV', ')', ';', 'Artificial', 'Intelligence', '(', 'cs.AI', ')', ';', 'Machine', 'Learning', '(', 'cs.LG', ')', \"''\", 'Object-Detection', ',', 'Machine', 'Learning', ',', 'Deep', 'Learning', 'Cost-effectiveness', 'analysis', ',', 'reference', 'case', ',', 'healthcare', 'perspective', ',', 'societal', 'perspective', ',', 'Impact', 'Inventory', ',', 'recommendations', 'health', ',', 'medicine', ',', 'biology', ',', 'science', 'antioxidant', ',', 'cancer', ',', 'dementia', ',', 'free', 'radicals', ',', 'heart', 'disease', ',', 'oxygen', 'radical', ',', 'reactive', 'species', ',', 'superoxide', 'dismutase', ',', 'Vitamin', 'E', ',', 'Vitamin', 'C', 'food', ',', 'agriculture', ',', 'globalization', ',', 'sustainable', 'food', ',', 'agriculte']\n"
     ]
    }
   ],
   "source": [
    "all_abstracts = [doc['abstract'] for doc in collection.find()]\n",
    "all_titles = [doc['title'] for doc in collection.find()]\n",
    "all_keywords = [doc['keywords'] for doc in collection.find()]\n",
    "\n",
    "abstract_corpus = create_corpus(\" \".join(all_abstracts))\n",
    "abstract_title = create_corpus(\" \".join(all_titles))\n",
    "abstract_keywords = create_corpus(\" \".join(all_keywords))\n",
    "\n",
    "all_tokens = abstract_corpus + abstract_title + abstract_keywords\n",
    "\n",
    "print(all_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector(model, tokens):\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vector += model.wv[token]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vector /= count\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_word2vec_model(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vector = get_doc_vector(trained_model, title_corpus)\n",
    "abstract_vector = get_doc_vector(trained_model, abstract_corpus)\n",
    "keywords_vector = get_doc_vector(trained_model, keywords_corpus)\n",
    "combined_vector = (title_vector + abstract_vector + keywords_vector) / 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = gm.Word2Vec.load('word2vec_model.gensim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector(model, tokens):\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vector += model.wv[token]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vector /= count\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03155997  0.08367068 -0.15792194 -0.00470785  0.03006019 -0.13455088\n",
      "  0.08710669  0.06378241  0.00053492  0.04914395 -0.06374766  0.02081904\n",
      "  0.05071698 -0.08516661 -0.10507596  0.03405641  0.01999462 -0.00848346\n",
      "  0.00405637  0.10875207  0.00262142 -0.03373197  0.03139705 -0.14057381\n",
      "  0.12232753 -0.03525893 -0.03811977  0.05390964 -0.10947495 -0.04903256\n",
      "  0.11561226  0.09439073  0.02204296  0.07413534  0.07627689  0.02014192\n",
      "  0.08648722 -0.03410613  0.0054055  -0.01100169  0.00848399 -0.05215172\n",
      "  0.05195323  0.01772907  0.00603381  0.01985251 -0.05696954  0.06967291\n",
      "  0.03055054  0.02048595 -0.01737124  0.11999004 -0.02444694  0.00872737\n",
      " -0.08657112  0.14161092 -0.02300335  0.11366222  0.04568678 -0.03823191\n",
      " -0.05003085 -0.03713296  0.00074726  0.02522048  0.03330199  0.01967213\n",
      " -0.03520566 -0.00940342 -0.07563626  0.10564117 -0.0425998   0.0161361\n",
      " -0.02162924  0.02132784 -0.05918821 -0.01843988  0.00470312  0.02932664\n",
      " -0.08717252 -0.03965257  0.00032097 -0.09099485  0.08882623  0.0692745\n",
      "  0.06823864  0.02689025 -0.0744413  -0.01491004  0.03482707 -0.06760313\n",
      " -0.00842264 -0.07098669 -0.01486242  0.00584968  0.07537438 -0.04645471\n",
      "  0.00234658 -0.17751348 -0.05439587  0.0645001  -0.13102171 -0.0413977\n",
      "  0.01157019 -0.06754368  0.07299604  0.0202137  -0.06823887  0.01453667\n",
      " -0.00757813  0.05980614 -0.1214329   0.03879902  0.0341168   0.06448804\n",
      "  0.11061496  0.00540478 -0.00776853 -0.13074878  0.0419891   0.01636128\n",
      "  0.02838661  0.07393804  0.05212799 -0.02718448 -0.09819903  0.02034486\n",
      "  0.032215   -0.05673381  0.02227761  0.00955688  0.09183868  0.04796355\n",
      " -0.00038139 -0.01509406  0.05242117 -0.07737934 -0.07196211 -0.07397553\n",
      " -0.05224748 -0.1089211   0.06642281 -0.10377947  0.05160776  0.07624734\n",
      "  0.01492229 -0.08949422 -0.13369959  0.09726809 -0.04170005 -0.03602249\n",
      "  0.00843249 -0.02858329 -0.10388644  0.04716891  0.01478942  0.0249157\n",
      "  0.08863844 -0.08884664 -0.03415906  0.15919696 -0.0036764   0.0945037\n",
      " -0.08330229  0.07224805 -0.13073567  0.00435146  0.07152966 -0.03612088\n",
      "  0.05704252 -0.0292364  -0.0331548   0.01488194  0.06489362  0.00753722\n",
      "  0.01527674 -0.0122173  -0.04281818  0.01805332 -0.08300154 -0.1097876\n",
      " -0.04472238  0.13026735  0.00432182  0.00033913  0.04130868  0.08363518\n",
      "  0.04649109 -0.03916862 -0.04519635  0.00718349  0.01985965 -0.02763224\n",
      " -0.10890111  0.01264399  0.00194624 -0.04449325 -0.10625404 -0.0866576\n",
      " -0.0529149  -0.02025607 -0.16334596  0.04041227 -0.05997124 -0.07439385\n",
      " -0.08612844  0.01371723  0.0283443   0.00468007 -0.08597729 -0.01958781\n",
      "  0.08338594 -0.00884406 -0.03472089 -0.01863539  0.07101954 -0.04296923\n",
      "  0.00627288 -0.12686938 -0.04226475  0.04878057 -0.01961871 -0.03934768\n",
      " -0.08854844 -0.04560293  0.02534498 -0.00502772 -0.08773038  0.01984513\n",
      " -0.11684338 -0.04171757 -0.0055044   0.05517079 -0.10096243  0.03819452\n",
      "  0.0142949   0.1026651   0.04442728  0.0686095   0.03043922 -0.17174688\n",
      " -0.01656859 -0.05660765 -0.09179092  0.00154402  0.03410571 -0.04406767\n",
      " -0.06299497 -0.03812719  0.01984869  0.12905001 -0.01644439  0.00191911\n",
      " -0.04327937  0.11261047 -0.10105643 -0.05321413  0.03057762  0.02459775\n",
      " -0.20192565 -0.06369651  0.01151153  0.06018891 -0.01532796 -0.06557041\n",
      "  0.06732844  0.0103927  -0.03502679 -0.03602595  0.02474626  0.06548378\n",
      "  0.03408786  0.03723379 -0.03876761 -0.04999771  0.12340419  0.08261585\n",
      "  0.06781578 -0.07655173 -0.03366059  0.00274421  0.09486373 -0.02500715\n",
      " -0.01871029  0.04118989 -0.03746317 -0.04261946 -0.02106151  0.05904105\n",
      " -0.13266632  0.14863666 -0.07100312  0.10657964  0.03399682  0.09375192\n",
      " -0.02323291  0.07976881 -0.08093205 -0.09728639  0.04702674 -0.05666527]\n"
     ]
    }
   ],
   "source": [
    "abstract_one = [doc['abstract'] for doc in collection.find()][0]\n",
    "example_abstract = preprocess_text(abstract_one)\n",
    "abstract_vector = get_doc_vector(load_model,example_abstract)\n",
    "\n",
    "keywords_one = [doc['keywords'] for doc in collection.find()][0]\n",
    "example_keywords = preprocess_text(keywords_one)\n",
    "keywords_vector = get_doc_vector(load_model,example_keywords)\n",
    "\n",
    "title_one = [doc['title'] for doc in collection.find()][0]\n",
    "example_title = preprocess_text(title_one)\n",
    "title_vector = get_doc_vector(load_model,example_title)\n",
    "\n",
    "combined_vector = (title_vector + abstract_vector + keywords_vector) / 3\n",
    "\n",
    "print(abstract_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def sentence_tokenization(text: str) -> List[List[str]]:\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(text)]\n",
    "    return tokenized_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Machine Learning\"\n",
    "query_tokens = preprocess_text(query_text)\n",
    "query_vector = np.mean([load_model.wv[word] for word in query_tokens if word in load_model.wv], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    query = [word for word in tokens if word not in stop_words]\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_vector(word2vec_model, query_tokens):\n",
    "    valid_tokens = [word for word in query_tokens if word in word2vec_model.wv]\n",
    "\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "    query_vector = np.mean([word2vec_model.wv[word] for word in valid_tokens], axis=0)\n",
    "    return query_vector\n",
    "\n",
    "# def get_query_vector(model, tokens):\n",
    "#     vector = np.zeros(model.vector_size)\n",
    "#     count = 0\n",
    "#     for token in tokens:\n",
    "#         if token in model.wv:\n",
    "#             vector += model.wv[token]\n",
    "#             count += 1\n",
    "#     if count != 0:\n",
    "#         vector /= count\n",
    "#     return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "# def calculate_cosine_similarity(vec1, vec2):\n",
    "#     return np.dot(vec1, vec2) / (np.linalg.norm(query_vector) * np.linalg.norm(vec2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 65e694c7afc3d58f1938551e\n",
      "Title: Machine Learning: A maturing field\n",
      "Similarity: 0.9330310821533203\n",
      "Abstract:\n",
      "With this volume I complete my four-year term as executive editor of Machine Learning,\n",
      "and Tom Dietterich, who has been co-executive editor with me recently, takes over the\n",
      "helm--or starts serving his sentence, depending upon one's point of view. Let me take this\n",
      "opportunity to make a few reflections about the state of the field; past, present and future,\n",
      "based on personal observations.\n",
      "A decade ago machine learning was regrouping from the rather uneventful 1970s. The\n",
      "first machine learning workshop was held in 1980 at Carnegie Mellon University with some\n",
      "two dozen participants and photocopied preprints. Shortly thereafter we started preparing\n",
      "the first machine learning book, and I was in charge of finding a publication venue. However\n",
      "the title \"Machine Learning\" raised skeptical eyebrows in publishers. By \"machine learning\" did we not really mean learning about machines rather than learning by machines?\n",
      "Couldn't we think of something more scientific-sounding to call the book? And anyway\n",
      "hadn't Minsky and Papert debunked this learning nonsense? Since it proved difficult to\n",
      "explain the difference between linear perceptrons and symbolic learning to those publishers\n",
      "(who shall go unnamed, to protect the guilty), we approached Nils Nilsson and his Tioga\n",
      "Press. Nils embraced the project with foresight and enthusiasm, and the rest, as they say\n",
      "in the tired cliche, is history.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e69605afc3d58f19385521\n",
      "Title: Deep learning\n",
      "Similarity: 0.9323300719261169\n",
      "Abstract:\n",
      "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e69647afc3d58f19385522\n",
      "Title: A survey on Image Data Augmentation for Deep Learning\n",
      "Similarity: 0.9309501051902771\n",
      "Abstract:\n",
      "Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e69688afc3d58f19385523\n",
      "Title: Towards Deep Learning Models Resistant to Adversarial Attacks\n",
      "Similarity: 0.9293375015258789\n",
      "Abstract:\n",
      "Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at this https URL and this https URL.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e695b3afc3d58f19385520\n",
      "Title: You Only Look Once: Unified, Real-Time Object Detection\n",
      "Similarity: 0.925618052482605\n",
      "Abstract:\n",
      "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e692c8afc3d58f1938551c\n",
      "Title: Automatic Facial Expression Analysis\n",
      "Similarity: 0.9218085408210754\n",
      "Abstract:\n",
      "Automatic Facial Expression Recognition systems have come a long way since the earliest approaches in the early 1970s. We are now at a point where the earliest systems are commercially applied, most notably the smile detectors in digital cameras. But although facial expression recognition is maturing as a research field, it is far from finished. New techniques continue to be developed on all aspects of the processing pipeline: from face detection, via feature extraction to machine learning. Nor is the field blind to the progress made in the social sciences with respect to emotion theory. Gone are the days that people only tried to detect six discrete expressions that were turned-on or off like the switching of lights. The theory of Social Signal Processing now complements classical emotion theory, and modern approaches dissect an expression into its temporal phases, analyse intensity, symmetry, micro-expressions and dynamic differences between morphologically similar expressions. Brave new worlds are opened up—Automatic Facial Expression Analysis is poised to revolutionalise medicine with the advent of behaviomedics, gaming with enriched player–non-player interactions, teleconference meetings with automatic trust and engagement analysis, and human–robot interaction with robots displaying actual empathy.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e696c5afc3d58f19385524\n",
      "Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\n",
      "Similarity: 0.9215884208679199\n",
      "Abstract:\n",
      "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e6914803a1e16834fb92d2\n",
      "Title: Communicating Ethics across the AI Ecosystem\n",
      "Similarity: 0.9213703870773315\n",
      "Abstract:\n",
      "Artificial Intelligence (AI) and machine learning (ML) are becoming increasingly ubiquitous in our everyday lives. Despite the rapid pace of these developments, debates around responsible AI and AI governance are still maturing. This paper outlines the growth of the ethical AI movement internationally and nationally to provide context for the CAIDG’s Ethics Hub Initiative. It touches on open questions in the field and discusses how these questions influenced the trajectory of the Hub’s research and methodologies.\n",
      "The paper reflects on the piloted empirical exercises and charts how research questions developed and changed over time. Along the way, we identified themes of power and resource differentials, as well as communication breakdowns that shaped the latter stages of our project.\n",
      "Given the nature of our pilot project, our findings are not indicative or generalizable of the entire field in Singapore. Nonetheless, they represent a meaningful snapshot of how debates around ethical AI and its operationalization are unfolding in Singapore and beyond. Ultimately, we encourage more focused research on the development and design of institutional incentive mechanisms to foster greater cohesion around responsible AI development and deployment norms.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e69521afc3d58f1938551f\n",
      "Title: Edge Assisted Real-Time Object Detection for Mobile and augmented Reality\n",
      "Similarity: 0.9205279350280762\n",
      "Abstract:\n",
      "Most existing Augmented Reality (AR) and Mixed Reality (MR) systems are able to understand the 3D geometry of the surroundings but lack the ability to detect and classify complex objects in the real world. Such capabilities can be enabled with deep Convolutional Neural Networks (CNN), but it remains difficult to execute large networks on mobile devices. Offloading object detection to the edge or cloud is also very challenging due to the stringent requirements on high detection accuracy and low end-to-end latency. The long latency of existing offloading techniques can significantly reduce the detection accuracy due to changes in the user's view. To address the problem, we design a system that enables high accuracy object detection for commodity AR/MR system running at 60fps. The system employs low latency offloading techniques, decouples the rendering pipeline from the offloading pipeline, and uses a fast object tracking method to maintain detection accuracy. The result shows that the system can improve the detection accuracy by 20.2%-34.8% for the object detection and human keypoint detection tasks, and only requires 2.24ms latency for object tracking on the AR device. Thus, the system leaves more time and computational resources to render virtual elements for the next frame and enables higher quality AR/MR experiences.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e94690f9ec29cf9fcd390e\n",
      "Title: Cost-Effectiveness in Health and Medicine (2nd edn)\n",
      "Similarity: 0.9154913425445557\n",
      "Abstract:\n",
      "As healthcare costs rise in the United States, debate is ongoing over how to obtain better value for dollars spent. In this context, the use of cost-effectiveness analysis (CEA) is more compelling than ever. This book, written by the Second Panel on Cost-Effectiveness in Health and Medicine, reviews key concepts and analytic challenges in CEA. The authors endorse the original Panel’s concept of a reference case and support its recommendation that analysts take a broad societal perspective; in addition, they recommend a healthcare sector perspective for a second reference case, as well as an important new framework, the Impact Inventory, for detailing costs and effects. The revisions draw on advances in the field and include three new chapters that capture research on decision modeling, methods for evidence synthesis, and ethical considerations. The volume also includes two new worked examples (Appendix A and Appendix B) to illustrate ways to implement the authors’ recommendations.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e696fdafc3d58f19385525\n",
      "Title: GLIMPSE: Continuous, Real-Time Object Recognition on Mobile Devices\n",
      "Similarity: 0.9153522253036499\n",
      "Abstract:\n",
      "\"Excerpted from \"\"Glimpse: Continuous, Real-Time Object Recognition on Mobile Devices\"\" from Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems with permission. http://dx.doi.org/10.1145/2809695.2809711 © ACM 2015.\n",
      "\n",
      "Glimpse is a continuous, real-time object recognition system for camera-equipped mobile devices. Glimpse captures full-motion video, locates objects of interest, recognizes and labels them, and tracks them from frame to frame for the user. Because the algorithms for object recognition entail significant computation, Glimpse runs them on server machines. When the latency between the server and mobile device is higher than a frame-time, this approach lowers object recognition accuracy. To regain accuracy, Glimpse uses an active cache of video frames on the mobile device. A subset of the frames in the active cache are used to track objects on the mobile, using (stale) hints about objects that arrive from the server from time to time. To reduce network bandwidth usage, Glimpse computes trigger frames to send to the server for recognizing.\"\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e946eff9ec29cf9fcd390f\n",
      "Title: Beyond the bedside: Clinicians as guardians of public health, medicine and science\n",
      "Similarity: 0.9104924201965332\n",
      "Abstract:\n",
      "This abstract delves into a conceptual framework that envisions clinicians not only as caregivers at the bedside but as pivotal guardians of public health, medicine, and science. The traditional role of clinicians has predominantly centered on individual patient care, yet this paradigm proposes an expansion of their responsibilities to encompass broader societal well-being. By exploring the intersections of clinical practice, public health initiatives, and scientific advancements, this paradigm shift aims to harness the expertise and influence of clinicians to address systemic health challenges.\n",
      "\n",
      "The proposed framework emphasizes the multifaceted roles clinicians can play in shaping public health policies, advancing medical research, and fostering a culture of evidence-based practice. Drawing on case studies and theoretical models, this abstract highlights the potential impact of empowering clinicians to contribute actively to public health discourse, policy formulation, and community education. It underscores the importance of integrating clinical knowledge with scientific inquiry, thereby fostering a more comprehensive approach to healthcare that transcends the confines of individual patient interactions.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e94813f9ec29cf9fcd3912\n",
      "Title: The Food and Agriculture Organization of the United Nations\n",
      "Similarity: 0.9092068672180176\n",
      "Abstract:\n",
      "One of the first of the specialized agencies of the United Nations to become active, the Food and Agriculture Organization has elicited interest beyond the specialized field of agricultural economists. Attempting as it does to solve one of the very basic problems of the world, that of an adequate food supply, the organization represents a significant and hopeful international attempt to create a world in which there may actually exist “freedom from want.” The objectives of FAO, as formally expressed in the preamble to the constitution, read as follows:\n",
      "\n",
      "“The nations accepting this constitution being determined to promote the common welfare by furthering separate and collective action on their part for the purpose of raising levels of nutrition and standards of living of the people under their jurisdiction, securing improvements in the efficiency of the production of all food and agricultural products, bettering the conditions of rural populations, and thus contributing toward an expanding world economy, hereby establish the Food and Agriculture Organization of the United Nations.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e94764f9ec29cf9fcd3910\n",
      "Title: Free Radicals in Biology and Medicine (5th edn)\n",
      "Similarity: 0.9058900475502014\n",
      "Abstract:\n",
      "The new edition of this well-established book is thoroughly revised and gives a comprehensive account of the role of free radicals, other reactive species (RS), and antioxidants in life, health, and disease. Chapter 1 reviews how oxygen (O2) is used by living organisms, why it can be toxic, and introduces the concept of oxygen radicals and other RS; their chemistry is detailed in Chapter 2, especially for superoxide, hydroxyl radical (including Fenton chemistry), peroxynitrite, nitric oxide, ozone, and singlet O2, with emphasis on their redox properties. Subsequent chapters detail what antioxidants can be made in vivo (e.g. superoxide dismutases, peroxiredoxins) and which can come from diet (e.g. vitamins E and C, carotenoids, and polyphenols such as the flavonoids) and how they work in vivo. The role of RS in cell proliferation, senescence, and death (e.g. by apoptosis, necrosis, or intermediate forms) is presented. Methods for measuring RS are described in detail, including electron paramagnetic resonance and biomarker determination. Useful roles for RS (e.g. cell signalling, phagocyte action), as well as systems in which they cause particular problems (e.g. premature babies, the eye, the ear) are presented. Acute and chronic inflammation are used to illustrate both roles There is a comprehensive description of the role of RS in human diseases, from cancer to heart disease to dementia, in the ageing process, and in the toxicity of many agents, from ethanol to carbon tetrachloride to paraquat. Therapeutic agents active against RS are reviewed in detail, including NADPH oxidase inhibitors, N-acetylcysteine, and Ebselen.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document ID: 65e947c0f9ec29cf9fcd3911\n",
      "Title: Global food demand and the sustainable intensification of agriculture\n",
      "Similarity: 0.8977419137954712\n",
      "Abstract:\n",
      "Global food demand is increasing rapidly, as are the environmental impacts of agricultural expansion. Here, we project global demand for crop production in 2050 and evaluate the environmental impacts of alternative ways that this demand might be met. We find that per capita demand for crops, when measured as caloric or protein content of all crops combined, has been a similarly increasing function of per capita real income since 1960. This relationship forecasts a 100-110% increase in global crop demand from 2005 to 2050. Quantitative assessments show that the environmental impacts of meeting this demand depend on how global agriculture expands. If current trends of greater agricultural intensification in richer nations and greater land clearing (extensification) in poorer nations were to continue, ~1 billion ha of land would be cleared globally by 2050, with CO(2)-C equivalent greenhouse gas emissions reaching ~3 Gt y(-1) and N use ~250 Mt y(-1) by then. In contrast, if 2050 crop demand was met by moderate intensification focused on existing croplands of underyielding nations, adaptation and transfer of high-yielding technologies to these croplands, and global technological improvements, our analyses forecast land clearing of only ~0.2 billion ha, greenhouse gas emissions of ~1 Gt y(-1), and global N use of ~225 Mt y(-1). Efficient management practices could substantially lower nitrogen use. Attainment of high yields on existing croplands of underyielding nations is of great importance if global crop demand is to be met with minimal environmental impacts.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Looking for information on natural language processing techniques.\"\n",
    "\n",
    "query_tokens = preprocess_text(query_text)\n",
    "query_vector = get_query_vector(load_model, query_tokens)\n",
    "\n",
    "most_relevant_docs = []\n",
    "\n",
    "for doc in collection.find():\n",
    "    doc_text = doc['abstract']\n",
    "    title = doc['title']\n",
    "    doc_corpus = create_corpus(doc_text)\n",
    "\n",
    "    doc_vector = get_query_vector(load_model, doc_corpus)\n",
    "\n",
    "    if np.all(doc_vector == 0) or np.all(query_vector == 0):\n",
    "        continue\n",
    "\n",
    "    similarity = cosine_similarity(query_vector.reshape(1, -1), doc_vector.reshape(1, -1))[0, 0]\n",
    "\n",
    "\n",
    "    if not np.isnan(similarity):\n",
    "        most_relevant_docs.append({'_id': doc['_id'],'title': title, 'similarity': similarity, 'abstract': doc_text})\n",
    "\n",
    "sorted_relevant_docs = sorted(most_relevant_docs, key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "num_abstracts_to_print = min(15, len(sorted_relevant_docs))\n",
    "for i in range(num_abstracts_to_print):\n",
    "    current_doc = sorted_relevant_docs[i]\n",
    "    print(f\"Document ID: {current_doc['_id']}\")\n",
    "    print(f\"Title: {current_doc['title']}\")\n",
    "    print(f\"Similarity: {current_doc['similarity']}\")\n",
    "    print(f\"Abstract:\\n{current_doc['abstract']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Machine Learning\"\n",
    "\n",
    "if query_text:\n",
    "    most_relevant_docs = find_most_relevant_docs(query_text, trained_model)\n",
    "    \n",
    "    num_abstracts_to_print = min(4, len(most_relevant_docs))\n",
    "    for i in range(num_abstracts_to_print):\n",
    "        current_doc = most_relevant_docs[i]\n",
    "        print(f\"Document ID: {current_doc['_id']}\")\n",
    "        print(f\"Title: {current_doc['title']}\")\n",
    "        print(f\"Similarity: {current_doc['similarity']}\")\n",
    "        print(f\"Abstract:\\n{current_doc['abstract']}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'Object':\n",
      "[-1.84465181e-02  5.52751832e-02 -1.80764437e-01 -3.21442378e-03\n",
      "  5.45954704e-02 -1.55086264e-01  1.02012619e-01  2.53448021e-02\n",
      " -4.17669350e-03  5.85578643e-02 -7.01204464e-02  3.50327902e-02\n",
      "  4.69067395e-02 -7.17622712e-02 -1.14778087e-01  5.09030484e-02\n",
      "  2.03295909e-02  6.06173510e-03 -3.53705324e-03  1.07207619e-01\n",
      "  3.69965807e-02 -1.79942679e-02  2.56782528e-02 -1.61340103e-01\n",
      "  1.29150152e-01 -3.58368978e-02 -2.38412973e-02  7.57606104e-02\n",
      " -8.48556235e-02 -5.57046756e-02  1.49535805e-01  8.66414085e-02\n",
      "  6.05413830e-03  1.16845272e-01  1.23310119e-01  1.02122501e-02\n",
      "  9.25629288e-02 -1.58022866e-02  3.31174731e-02  1.26188237e-03\n",
      "  1.37213487e-02 -6.63524941e-02  8.83114859e-02  1.21228546e-02\n",
      "  1.55048007e-02  3.29682156e-02 -6.26884401e-02  8.57784152e-02\n",
      "  3.97493280e-02  2.07431186e-02 -4.67517599e-02  1.25401333e-01\n",
      " -7.95861986e-03  1.27465129e-02 -9.56636146e-02  1.67142794e-01\n",
      " -4.19650786e-02  1.45488322e-01  6.46685660e-02 -1.04867192e-02\n",
      " -4.19376753e-02 -4.18789200e-02 -1.74253702e-03  4.06387895e-02\n",
      "  3.49729322e-02  1.80917587e-02 -4.06290255e-02  1.51200918e-04\n",
      " -6.24870360e-02  1.37998328e-01 -4.42988053e-02 -4.15414013e-03\n",
      " -4.44829501e-02  3.60210203e-02 -3.27378884e-02 -6.43079774e-03\n",
      "  2.17932910e-02  3.36817168e-02 -1.33996323e-01 -7.33899921e-02\n",
      " -1.82003975e-02 -6.42465949e-02  6.63569495e-02  6.99815601e-02\n",
      "  8.11703503e-02  3.94809581e-02 -8.40737745e-02 -1.35999639e-02\n",
      "  2.51948014e-02 -1.12835377e-01 -4.08364236e-02 -5.80589287e-02\n",
      " -2.47149356e-02  1.65051688e-02  6.43724874e-02 -5.68443052e-02\n",
      " -1.66770034e-02 -2.06363782e-01 -7.07159489e-02  5.02807498e-02\n",
      " -1.44931182e-01 -3.54074277e-02 -7.18141487e-03 -7.10712150e-02\n",
      "  6.07319474e-02  5.44466972e-02 -8.00730735e-02  4.00945432e-02\n",
      "  9.32490826e-03  6.54088035e-02 -1.20553747e-01  5.70999123e-02\n",
      "  4.03685458e-02  6.37317821e-02  1.13204166e-01  2.41961852e-02\n",
      "  4.41266317e-03 -1.54114768e-01  3.36792283e-02  4.03525345e-02\n",
      " -1.37151554e-02  9.19859633e-02  5.02710827e-02 -4.60282713e-02\n",
      " -9.68320370e-02  1.85848065e-02  1.93710718e-02 -4.79290746e-02\n",
      "  4.16239128e-02  3.55105638e-03  8.57520103e-02  2.77791396e-02\n",
      "  2.01079343e-02 -1.47450389e-02  5.09767272e-02 -1.11143604e-01\n",
      " -9.54724103e-02 -8.94290432e-02 -1.79036111e-02 -1.31570369e-01\n",
      "  5.05097508e-02 -9.74027663e-02  4.53158766e-02  8.31676275e-02\n",
      " -1.58228143e-03 -1.28455415e-01 -1.29080057e-01  1.05085820e-01\n",
      " -6.49610981e-02 -3.41336951e-02 -1.19157124e-03 -4.09998436e-04\n",
      " -1.08181529e-01  5.47923520e-02  1.87124442e-02  4.29214314e-02\n",
      "  1.22256599e-01 -8.47062171e-02 -1.93865076e-02  1.78277746e-01\n",
      "  5.11401985e-03  7.45512098e-02 -6.02398813e-02  8.05704296e-02\n",
      " -1.59628600e-01 -8.86389520e-03  4.82820012e-02 -5.16409008e-03\n",
      "  3.52554880e-02 -6.65253699e-02 -3.93925309e-02  3.86171928e-03\n",
      "  8.62211138e-02  9.60123166e-03  4.04121205e-02 -1.55682312e-02\n",
      " -1.35728177e-02  2.20665894e-02 -7.91341141e-02 -8.35283920e-02\n",
      " -4.77882624e-02  1.49198279e-01  3.05443518e-02  2.33162083e-02\n",
      "  7.80231729e-02  9.58328098e-02  3.73462588e-02 -3.25506851e-02\n",
      " -5.17913438e-02  2.53234506e-02  3.83526925e-03 -2.51910575e-02\n",
      " -1.13450475e-01  2.26777066e-02  2.28680484e-03 -1.92464814e-02\n",
      " -1.20775394e-01 -7.77798146e-02 -7.99267516e-02 -1.65158194e-02\n",
      " -1.82985783e-01  2.37370748e-02 -6.33375943e-02 -3.23937684e-02\n",
      " -8.45463797e-02  3.56334001e-02  7.42089823e-02 -4.47044848e-03\n",
      " -1.07742667e-01 -1.88075528e-02  9.29825678e-02  5.83857810e-03\n",
      " -4.06628549e-02 -2.11038832e-02  6.32534549e-02 -7.70897046e-03\n",
      " -1.18764304e-02 -1.23644561e-01 -2.95765754e-02  6.58691227e-02\n",
      " -3.50778140e-02 -2.15452295e-02 -9.46901888e-02 -4.72992994e-02\n",
      "  6.72944784e-02  1.17060645e-02 -9.48376656e-02  1.61660332e-02\n",
      " -1.53789684e-01 -5.64282872e-02 -1.93922259e-02  4.01668996e-02\n",
      " -1.28108725e-01  5.70031814e-02  1.23004122e-02  1.02264710e-01\n",
      "  4.71801981e-02  7.42954314e-02  2.78838240e-02 -1.66607112e-01\n",
      "  6.73625572e-03 -7.07591847e-02 -1.07006684e-01  2.05193292e-02\n",
      "  2.71590445e-02 -7.27390796e-02 -7.40447491e-02 -7.98826665e-02\n",
      "  3.53318192e-02  1.24588214e-01 -8.33231141e-04 -2.05067359e-02\n",
      " -4.01570313e-02  1.15698814e-01 -1.19033612e-01 -7.28545859e-02\n",
      "  2.84230094e-02  5.16172638e-03 -2.33646646e-01 -9.79816392e-02\n",
      " -1.40506532e-02  6.14579096e-02 -2.93469392e-02 -6.74918294e-02\n",
      "  9.42244306e-02  2.34937808e-03 -5.48728406e-02 -2.30071153e-02\n",
      "  3.13815773e-02  4.41027768e-02  6.05055392e-02  4.48212251e-02\n",
      " -4.08170372e-02 -5.38845509e-02  1.36662185e-01  9.58212763e-02\n",
      "  5.79345673e-02 -6.89589530e-02 -3.21892165e-02  1.09822638e-02\n",
      "  8.52908492e-02 -3.13437469e-02 -8.89197458e-03  4.82156463e-02\n",
      " -4.65715602e-02 -3.15585323e-02  3.90832685e-03  5.55871278e-02\n",
      " -1.61495551e-01  1.33398086e-01 -6.50339052e-02  1.38008416e-01\n",
      "  3.23225632e-02  1.46762401e-01 -4.28986289e-02  7.15766326e-02\n",
      " -9.23691690e-02 -1.19114116e-01  4.26588282e-02 -7.26340488e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vector = trained_model.wv['ai']\n",
    "print(f\"Vector for 'Object':\\n{word_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('applications', 0.9993378520011902),\n",
       " ('standard', 0.9993376731872559),\n",
       " ('remain', 0.9992969036102295),\n",
       " ('pre-trained', 0.9992912411689758),\n",
       " ('attention', 0.9992780685424805),\n",
       " ('conjunction', 0.9992536306381226),\n",
       " ('place', 0.9992276430130005),\n",
       " ('url', 0.9992267489433289),\n",
       " ('URL', 0.9992247819900513),\n",
       " ('available', 0.9992191195487976)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.wv.most_similar(positive=['language'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
